## AI资讯 2025/9/7

>  `AI 日报` 



### **AI内容摘要**

```
一项调查显示，25%美国年轻人愿与AI谈恋爱，11%希望有AI朋友，男性接受度更高。  
OpenAI重组团队并发布论文，指出AI幻觉源于训练机制和评估缺陷，建议重罚自信错误。  
字节发布全能机器人模型Robix，微软提出数据排序新范式DELT，Anthropic以15亿美元和解版权诉讼。
```



### **Today's AI News**

1. 最近一项针对**2000名**美国年轻人的调查显示，**四分之一**的年轻人愿意接受与**AI谈恋爱**，而**11%** 的人希望拥有**AI朋友**。更有意思的是，**男性**比女性更愿意接受AI作为朋友（13% vs 9%），自由派也比保守派更容易拥抱AI友情（14% vs 9%）。

2. 为什么年轻人会想和AI谈恋爱？或许是因为AI能提供**无压力的情感支持**。例如，Character.AI平台上的"心理医生”机器人已收到近**9500万条消息**，很多网友反馈AI对自己的心理帮助很大。情感类"角色扮演”已成为生成式AI的第二大热门应用，仅次于"创意写作”。

3. 不过，不是所有人都买账。**57%** 的受访者明确反对与AI做朋友，认为这"有悖伦理”或"令人不适”。而在AI恋爱方面，**71%** 的年轻人表示反对，仅**7%** 的单身者持开放态度。

4. 有趣的是，尽管Z世代和千禧一代对AI恋爱的接受度接近，但**Z世代反而更反对**（74% vs 67%）。收入和教育水平也影响看法——高收入、高学历人群更可能拒绝AI伴侣。

5. 除了情感关系，人们对**AI技术本身的态度也两极分化**：**55%** 的人认为AI令人担忧，**45%** 的人则感到兴奋。女性、保守派、低收入人群对AI更警惕。

6. 这些数据或许预示着一个新趋势：人类的亲密关系正从"人人连接”转向"**人机共建**”。

7. **OpenAI**最近进行了一场重磅组织调整：负责**ChatGPT"个性”** 的**模型行为团队**被并入**后训练团队**，原负责人**Joanne Jang**转去领导新成立的**OAI Labs**，专注探索下一代人机交互界面。

8. 为什么突然调整？OpenAI罕见发布论文自揭老底：**AI"幻觉”（胡说八道）的罪魁祸首，竟是我们自己！**

9. 目前的AI评估体系就像一场"**应试教育**”——模型为了在排行榜拿高分，宁愿"蒙答案”也不肯说"我不知道”。因为"留白”是零分，而"瞎猜”还有蒙对的概率。这种"唯准确率论”的评估方式，无形中**奖励了模型的不诚实行为**。

10. OpenAI举例：当问AI"某人的生日是哪天”，它可能会自信地给出三个错误答案。这就是"**自信地犯错**”。

11. 怎么解决？OpenAI建议：应该**重罚"自信错误”**，并**奖励"诚实弃权”**。就像考试时"答错倒扣分”，让AI学会"不会就放弃”。

12. 论文还澄清了几个常见误解：幻觉不能100%消除，但可以控制；不是模型越大越能避免幻觉，有时小模型反而更清楚自己的局限；幻觉不是神秘故障，而是统计学机制 + 错误评估导向的结果。

13. 这次重组+论文发布，可能正在改写AI的能力边界。未来，我们或许会看到更"诚实”的AI。

14. 字节跳动发布了**Robix**——一款能同时搞定**机器人推理**、**任务规划**和**自然语言交互**的"全能大模型”。终于，机器人不用再靠"散装模块”拼凑大脑了！

15. 以往，让机器人干活非常麻烦：听懂人话要一个模块，规划路径要另一个模块，模块之间还经常"沟通不畅”。而Robix采用**视觉-语言融合架构**，把三大功能整合进**单一模型**，用**思维链推理**一步步"思考”该怎么做。

16. 训练过程分三阶段：**持续预训练**：学习3D空间、语言-画面对应；**监督微调**：模拟真实场景（如收拾餐桌、超市购物）；**强化学习**：通过"奖励-惩罚”让决策更稳、动作更准。

17. 效果如何？Robix在多项测试中超越了**GPT-4o**、**Gemini 2.5 Pro**等闭源模型。在真实机器人评估中，Robix-32B的平均任务进度达到**92.5%**，比GPT-4o高出28个百分点！

18. 该项目由字节AI实验室负责人**李航**博士带队。他曾在华为诺亚方舟实验室担任首席科学家，2017年加入字节后主导机器人研发。虽然今年6月传出他退休的消息，但字节表示他仍将以顾问身份继续工作。

19. 看来，机器人模型的未来不再是"拼模块”，而是"**拼综合能力**”。一个模型干所有事，可能才是终极答案。

20. **微软亚洲研究院**提出了一种名为**DELT**的全新文本数据组织范式，核心发现是：**训练数据的出场顺序**对模型性能有巨大影响，甚至比单纯增加数据量或扩大模型规模更有效。

21. 这就像**给学生安排课程表**——不是把所有知识一次性塞进去，而是根据**难度、质量和多样性**精心编排学习顺序。DELT通过**数据评分、数据选择和数据排序**三大步骤，让模型在**不增加任何成本**的情况下，显著提升在通用、数学和代码等多个领域的表现。

22. 其中，他们还提出了创新的**折叠排序法（Folding Ordering）**，避免模型因固定学习顺序而产生"偏科”或遗忘问题。这一方法为**以数据为中心的AI**（Data-centric AI）提供了全新思路。

23. OpenAI最新研究指出，AI模型的**幻觉**（即自信地输出错误信息）并非偶然bug，而是其**训练机制和评估体系**的必然结果。

24. 幻觉的两大根源：**训练方式问题**：模型通过"预测下一个词”学习，但训练数据中只有"正确样本”，没有"错误样本”标签。导致模型学会了**语言的流畅性**，却**分不清事实与虚构**；**评估机制缺陷**：目前的评估大多只奖励"答对率”，就像考试中"蒙对了能得分，不答就是零分”。这种机制**鼓励模型盲目猜测**，而不是诚实地说"我不知道”。

25. 如何解决？OpenAI建议**调整评估标准**，对"自信的错误”施加更重惩罚，对"谨慎的不回答”给予部分奖励。换句话说，**要让AI学会谦虚**，而不是盲目自信。

26. 研究还澄清了几个常见误区：幻觉不能靠更大模型解决；小模型有时反而更诚实；幻觉不是神秘故障，而是可解释的统计现象。

27. AI公司**Anthropic**同意支付**15亿美元**，和解一起由作家集体发起的版权诉讼。这些作家指控Anthropic通过盗版网站下载了超过**700万本书**，用于训练其AI模型Claude。

28. 和解关键点：平均每本书获赔约**3000美元**；Anthropic同意**销毁所有盗版数据及副本**；这是美国版权史上最高金额的和解案之一。

29. 争议仍在继续：虽然和解金额巨大，但有人认为这对Anthropic来说只是"洒洒水”——他们刚完成**130亿美元融资**，年收入超**50亿美元**。更关键的是，**和解并不代表法律认定AI训练构成侵权**，核心的"合理使用”争议仍未解决。

30. 与此同时，**苹果、华纳兄弟等公司也面临类似诉讼**，AI公司与内容创作者之间的版权博弈仍在持续。

31. 这一周的AI新闻仿佛一场"技术-伦理-法律”的三幕剧：**技术层面**，我们越来越会"教”AI了；**伦理层面**，我们开始反思AI为何"不诚实”；**法律层面**，AI与版权之间的边界仍在模糊中探索。

32. AI不再只是算法问题，更是**社会、法律与人性**的交汇点。未来的AI发展，必须在创新与责任之间找到平衡。

33. 最近，科技圈爆出一则让人有点"懵”的消息：**英伟达**居然花了**15亿美元**，向一家小型云服务商**Lambda**租用搭载自家AI芯片的服务器。听起来像不像"自己买自己的东西还付钱”？别急，这背后其实是一场精妙的商业布局。

34. 简单来说，英伟达先投资Lambda，Lambda用这笔钱买英伟达的芯片，然后英伟达再花钱租用这些服务器。钱转了一圈，但效果却很显著：Lambda收入大涨，IPO可能性飙升；英伟达既卖了芯片，又当了股东，还巩固了市场地位。这招"内循环”玩法，英伟达已经不是第一次用了——之前对**CoreWeave**的操作如出一辙，结果后者成功上市，成了科技圈的大新闻。

35. 为什么英伟达要这么折腾？原因很简单：**微软、谷歌、亚马逊**等大客户都在自研AI芯片，未来可能变成竞争对手。英伟达通过扶持这些小公司，打造"联盟”，既能稳住芯片销量，又能牵制大厂，可谓一举多得。

36. AI最让人头疼的问题是什么？不是宕机，也不是答非所问，而是**幻觉**——模型一本正经地胡说八道，还显得特别自信。最近，**OpenAI**罕见发布论文，系统性地揭秘了幻觉的根源。

37. **什么是幻觉？** 简单说，就是模型生成看似合理但完全错误的信息。比如问不同聊天机器人"某人的