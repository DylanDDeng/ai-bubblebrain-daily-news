---
title: "Bubble's Brain - 2026-01-01"
date: 2026-01-01T09:00:00+08:00
description: "Bubble's Brain - 2026年1月1日"
categories:
  - 日报
tags:
  - AI
  - 人工智能
  - 行业动态
draft: false
---

## AI资讯 2026/1/1

>  `AI 日报` 



### **AI内容摘要**

```
AI21Labs澄清与英伟达无具体交易，小米延长MiMo-V2-Flash公测期并公布定价。月之暗面完成5亿美元C轮融资，不急于IPO并计划加大员工激励。YuanLab.ai开源多模态大模型，腾讯混元开源文本到3D动作生成模型。分析指出AI套壳产品需深度嵌入工作流，OpenAI员工股票薪酬创历史新高。专家认为AI智能增长瓶颈在于技术范式难以高效消化算力增长。
```



### **Today's AI News**

1.  以色列人工智能公司 **AI21Labs** 的首席执行官 Ori Goshen 在一份内部信中澄清，公司与**英伟达**并未达成任何具体的交易协议。他承认公司正在与包括英伟达在内的多家潜在合作方进行保密洽谈，但强调讨论仍在进行中，且不意味着即将有重大变化。AI21Labs 运营一切正常，并承诺若有实质性进展将第一时间透明地通知员工。

2.  小米宣布将其自研大模型 **MiMo-V2-Flash** 的免费公测期延长20天，新的截止日期为2026年1月20日下午2点。MiMo-V2-Flash 是一款参数量达3090亿的开源大模型。小米同时公布了该模型的 **API** 定价策略，国内用户输入和输出费用分别为每百万 tokens 0.7元和2.1元，海外用户则为每百万 tokens 0.1美元和0.3美元。

3.  国内大模型公司**月之暗面（Moonshot AI）** 近日完成5亿美元 **C 轮融资**，公司账面现金储备已突破100亿元人民币。创始人兼CEO杨植麟表示，充裕的资金让公司"不急于 **IPO**”，可以更从容地进行长周期技术研发。公司计划在2026年将员工激励力度翻倍，并明确其目标是超越国际前沿初创公司，冲击世界领先的 **AGI** 公司地位。

4.  **YuanLab.ai** 团队近日发布了开源的**源 Yuan3.0Flash** 多模态基础大模型。该模型参数规模达400亿，采用创新的**稀疏混合专家架构**，在推理时仅激活约37亿参数，显著降低了算力消耗。模型提供了多种权重版本及详细技术报告，支持二次开发。在实际企业应用中，其在多项任务上的表现已超越 **GPT-5.1**，且推理成本仅为同类大模型的四分之一到二分之一。未来，团队还将推出参数规模涵盖400亿至1万亿的更多版本。

5.  腾讯**混元**团队于2025年12月30日开源了名为 **HY-Motion1.0** 的文本到3D动作生成大模型。该模型拥有百亿参数，基于 **Diffusion Transformer** 架构，用户仅需一句文本描述即可生成高质量的3D角色骨骼动画，并可直接导入主流3D工具。模型覆盖六大类超200种动作，在社区实测中表现亮眼，尤其在指令遵循能力和动作质量上超越了多个开源基线模型。该模型有望大幅降低游戏、影视等领域的动画制作门槛，其轻量版也已同步开源。

6.  针对市场上涌现的大量"**AI套壳**”产品，一项新分析指出，其能否在竞争中存活，关键在于能否深度嵌入用户工作流并积累独特数据。文章区分了易被平台功能取代的"功能型”应用和能建立自身壁垒的"产品型”应用。创业公司面临依赖大模型技术却又需与巨头竞争渠道的双重挑战。分析强调，成功的套壳产品必须与用户实际工作流程紧密结合，提供能解决具体问题的有效方案，而不仅仅是简单工具。

7.  **OpenAI** 最新财务报告显示，该公司向约 4000 名员工支付的**股票薪酬**人均高达 150 万美元，创下科技初创公司历史新高。这一数字是过去 25 年里其他 18 家主要科技公司在上市前一年员工薪酬的 34 倍。分析预计，到 2030 年前，OpenAI 每年将为员工发放约 30 亿美元的股票薪酬。此外，公司取消了员工获得股票的归属期政策，此举可能进一步推高薪酬水平以吸引顶尖人才。预计到 2025 年，OpenAI 的员工薪酬将占公司收入的 46%，这一比例在科技行业中处于领先地位。

8.  新加坡国立大学教授**尤洋**撰文指出，当前**AI智能增长**的瓶颈，并非算力停止增长，而是现有技术范式难以高效"消化”持续增长的算力。他认为，智能的核心是"对未来状态进行预测，并为预测结果承担实际后果的能力”。**Transformer**架构的成功，本质上是其作为"并行计算机”的特性与**GPU**硬件体系高度匹配的结果。文章提出，真正的挑战在于能否找到一种扩展性更强的架构或损失函数，将新增算力稳定地转化为可兑现的能力增量。未来可能的探索方向包括更高精度计算、改进优化器、更可扩展的架构等。